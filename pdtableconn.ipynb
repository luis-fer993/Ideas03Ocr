{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pasos para optimizacion de procesos\n",
    "\n",
    "- Acceso a datos y manipulacion de los datos \n",
    "  - Lectura de archivo original \n",
    "  - Busqueda de datos segun criterios en filas y columnas \n",
    "  - Filtro con las columnas necesitadas \n",
    "- Creacion de rango de consulta en columnas \n",
    "- Lectura de numeros mediante el uso de OCR y reconocimiento de imagenes\n",
    "  - Mediante el uso de librerias de reconocimiento de imagenes se extrae el texto \n",
    "  - Se crea una seleccion especifica en el area especificada de la imagen\n",
    "    - se manipula la imagen seleccionando el area especifica de texto o numero \n",
    "  - se extrae el texto o se digita manualmente  \n",
    "- Consulta a base de datos con los datos obtenidos \n",
    "  - Se establece una conexxion a base de datos con los parametros establecidos\n",
    "  - Utillizando la informacion obtenida se realiza la consulta y se obtienen los datos devueltos \n",
    "- Creacion de DataFrame de acuerdo a las condiciones establecidas\n",
    "  - se realiza un modelo que reune:\n",
    "    - la informacion original, ubicada en el orden respectivo de columnas\n",
    "    - se establece la informacion en las coluymnas requeridas de acuerdo a los datos obtenidos en la base de datos \n",
    "    - se pone la debida informacion de acuerdo a las condiciones dadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip remove mysql-connector-python\n",
    "\n",
    "#! pip freeze > requirements.txt\n",
    "# ! pip install -r requirements.txt\n",
    "#! pip install flask_mysqldb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       https://shortextraction.grupomeiko.io/20230630...\n",
       "1       https://shortextraction.grupomeiko.io/20230630...\n",
       "2       https://shortextraction.grupomeiko.io/20230630...\n",
       "3       https://shortextraction.grupomeiko.io/20230630...\n",
       "4       https://shortextraction.grupomeiko.io/20230630...\n",
       "                              ...                        \n",
       "6178    https://shortextraction.grupomeiko.io/20230403...\n",
       "6179    https://shortextraction.grupomeiko.io/20230403...\n",
       "6180    https://shortextraction.grupomeiko.io/20230403...\n",
       "6181    https://shortextraction.grupomeiko.io/20230403...\n",
       "6182    https://shortextraction.grupomeiko.io/20230404...\n",
       "Name: FotoStickerFemsa, Length: 6183, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import os\n",
    "\n",
    "csvFile = pd.read_csv('mt1.csv')\n",
    "\n",
    "csvFile[['FotoStickerFemsa','CodifoclienteKof_Mex','Tiene match?']].head()\n",
    "csvFile[['FotoStickerFemsa'][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Place_id': '74b9c3d7c1d9b0045b7535de2531c8a7', 'Ciclo': '423', 'idRegistroEncuesta': 6351985, 'idEstablecimiento': 880817, 'NombreEstablecimiento': 'la cantina', 'Direccion': 'TULTITLAN.25.1.3.E', 'FotoStickerFemsa': 'https://shortextraction.grupomeiko.io/20230403/624_2936888_FotoStickerFemsa.jpg', 'Imagen': nan, 'CodifoclienteKof_Mex': nan, 'Tiene match?': nan, 'IdEstablecimeinto Matcheado': nan, 'Unnamed: 11': nan}, {'Place_id': 'b717c02fa1baa9cda67399598f4fc124', 'Ciclo': '423', 'idRegistroEncuesta': 6350671, 'idEstablecimiento': 880748, 'NombreEstablecimiento': 'Abarrotes beto', 'Direccion': 'CIUDAD DE MEXICO.9.3.2.F', 'FotoStickerFemsa': 'https://shortextraction.grupomeiko.io/20230404/624_2925679_FotoStickerFemsa.jpg', 'Imagen': nan, 'CodifoclienteKof_Mex': 'No aplica', 'Tiene match?': 'No aplica', 'IdEstablecimeinto Matcheado': 'No aplica', 'Unnamed: 11': nan}]\n",
      "[{'Ciclo': '423',\n",
      "  'CodifoclienteKof_Mex': nan,\n",
      "  'Direccion': 'TULTITLAN.25.1.3.E',\n",
      "  'FotoStickerFemsa': 'https://shortextraction.grupomeiko.io/20230403/624_2936888_FotoStickerFemsa.jpg',\n",
      "  'IdEstablecimeinto Matcheado': nan,\n",
      "  'Imagen': nan,\n",
      "  'NombreEstablecimiento': 'la cantina',\n",
      "  'Place_id': '74b9c3d7c1d9b0045b7535de2531c8a7',\n",
      "  'Tiene match?': nan,\n",
      "  'Unnamed: 11': nan,\n",
      "  'idEstablecimiento': 880817,\n",
      "  'idRegistroEncuesta': 6351985},\n",
      " {'Ciclo': '423',\n",
      "  'CodifoclienteKof_Mex': 'No aplica',\n",
      "  'Direccion': 'CIUDAD DE MEXICO.9.3.2.F',\n",
      "  'FotoStickerFemsa': 'https://shortextraction.grupomeiko.io/20230404/624_2925679_FotoStickerFemsa.jpg',\n",
      "  'IdEstablecimeinto Matcheado': 'No aplica',\n",
      "  'Imagen': nan,\n",
      "  'NombreEstablecimiento': 'Abarrotes beto',\n",
      "  'Place_id': 'b717c02fa1baa9cda67399598f4fc124',\n",
      "  'Tiene match?': 'No aplica',\n",
      "  'Unnamed: 11': nan,\n",
      "  'idEstablecimiento': 880748,\n",
      "  'idRegistroEncuesta': 6350671}]\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "f1=csvFile.tail(5)\n",
    "f2=csvFile.tail(2)\n",
    "f1=f1.to_numpy()\n",
    "\n",
    "f2=f2.to_dict(orient='records')\n",
    "\n",
    "print(f2)\n",
    "\n",
    "pprint.pprint(f2)\n",
    "\n",
    "#for item in f1:\n",
    "#    for val in item:\n",
    "#        print(val)\n",
    "#    \n",
    "#    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Place_id   Ciclo  idRegistroEncuesta  \\\n",
      "0  e6a76b04bf2491c7b29d07abd4ff7af8     623             6865944   \n",
      "1  1398082a5e7548eeeecd1f2353aadce8     623             6865940   \n",
      "2  3ff1065da3fdd1b2cd827e2727b2f3ef     623             6865833   \n",
      "3  ba2559ced84fb382e31cd189d03c495c     623             6865832   \n",
      "4  6db38c59aa36597f98125afc76cbf822  subido             6865829   \n",
      "\n",
      "   idEstablecimiento    NombreEstablecimiento               Direccion  \\\n",
      "0             980606   mivelanea la escondida        ZUMPANGO.46.1.1.   \n",
      "1             980602  Abarrotes Rosales Rojas        ZUMPANGO.46.1.1.   \n",
      "2             980598    antobitog msry y meme  NEZAHUALCOYOTL.1.4.3.B   \n",
      "3             980597           alitad y beear  NEZAHUALCOYOTL.1.4.3.A   \n",
      "4             928076              el progreso    CHIMALHUACAN.1.3.6.A   \n",
      "\n",
      "                                    FotoStickerFemsa  Imagen  \\\n",
      "0  https://shortextraction.grupomeiko.io/20230630...     NaN   \n",
      "1  https://shortextraction.grupomeiko.io/20230630...     NaN   \n",
      "2  https://shortextraction.grupomeiko.io/20230630...     NaN   \n",
      "3  https://shortextraction.grupomeiko.io/20230630...     NaN   \n",
      "4  https://shortextraction.grupomeiko.io/20230630...     NaN   \n",
      "\n",
      "  CodifoclienteKof_Mex                      Tiene match?  \\\n",
      "0            No aplica                         No aplica   \n",
      "1            No aplica                         No aplica   \n",
      "2            No aplica                         No aplica   \n",
      "3            No aplica                         No aplica   \n",
      "4            105311121  SI , idestablecimiento Diferente   \n",
      "\n",
      "  IdEstablecimeinto Matcheado Unnamed: 11  \n",
      "0                   No aplica   NO aplica  \n",
      "1                   No aplica   NO aplica  \n",
      "2                   No aplica   NO aplica  \n",
      "3                   No aplica   NO aplica  \n",
      "4                      759394     ajustar  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "#csvFile.info()# show info type data frame\n",
    "\n",
    "#type(csvFile.columns)\n",
    "\n",
    "data=csvFile.head()\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 5 entries, 978 to 983\n",
      "Data columns (total 3 columns):\n",
      " #   Column                Non-Null Count  Dtype \n",
      "---  ------                --------------  ----- \n",
      " 0   idEstablecimiento     5 non-null      int64 \n",
      " 1   FotoStickerFemsa      5 non-null      object\n",
      " 2   CodifoclienteKof_Mex  0 non-null      object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 160.0+ bytes\n",
      "https://shortextraction.grupomeiko.io/20230626/626_3596995_FotoStickerFemsa.jpg\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "#filter just empy fields in 'CodifoclienteKof_Mex'\n",
    "data1=csvFile.loc[csvFile['CodifoclienteKof_Mex'].notna()==False,['idEstablecimiento','FotoStickerFemsa','CodifoclienteKof_Mex']].head(5) #obtenenemos las filas que no tienen Codigo Aun\n",
    "\n",
    "#print the selected colums and description\n",
    "data1.info()\n",
    "print(data1.values[0][1])\n",
    "print(data1.values[0][1]=='https://shortextraction.grupomeiko.io/20230626/626_3596995_FotoStickerFemsa.jpg')\n",
    "#csvFile[['FotoStickerFemsa']].head(5) #obtenenemos las filas que no tienen Codigo Aun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\luis.chaparro\\Documents\\coding-py\\ocr\\pdtableconn.ipynb Cell 7\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/luis.chaparro/Documents/coding-py/ocr/pdtableconn.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpathlib\u001b[39;00m \u001b[39mimport\u001b[39;00m Path \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/luis.chaparro/Documents/coding-py/ocr/pdtableconn.ipynb#W6sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m FilePathBase\u001b[39m=\u001b[39mPath(\u001b[39m'\u001b[39m\u001b[39mdb\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mBaseEstudios.csv\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/luis.chaparro/Documents/coding-py/ocr/pdtableconn.ipynb#W6sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m newEdit\u001b[39m=\u001b[39mpd\u001b[39m.\u001b[39mread_csv(FilePathBase)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/luis.chaparro/Documents/coding-py/ocr/pdtableconn.ipynb#W6sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m dataList\u001b[39m=\u001b[39m{}\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/luis.chaparro/Documents/coding-py/ocr/pdtableconn.ipynb#W6sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m dataList[\u001b[39m'\u001b[39m\u001b[39midtabla\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m=\u001b[39m\u001b[39mint\u001b[39m(\u001b[39m3\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "from pathlib import Path \n",
    "FilePathBase=Path('db','BaseEstudios.csv')\n",
    "\n",
    "newEdit=pd.read_csv(FilePathBase)\n",
    "dataList={}\n",
    "dataList['idtabla']=int(3)\n",
    "dataList['estudio']='EDGE2'\n",
    "dataList['descripcion']='pruebaaplicativos01'\n",
    "dataList['idestudio']=int(555)\n",
    "\n",
    "idEspecifico=newEdit.loc[newEdit['idtabla']==dataList['idtabla']]\n",
    "#idEspecifico[['estudio']]=dataList['estudio']\n",
    "#idEspecifico[['descripcion']]=dataList['descripcion']\n",
    "#idEspecifico[['idestudio']]=dataList['idestudio']\n",
    "#idEspecifico['estudio']=dataList['estudio']\n",
    "newEdit.loc[int(idEspecifico.index[0]),'descripcion']='new9'\n",
    "\n",
    "for val in  idEspecifico.keys():\n",
    "    newEdit.loc[int(idEspecifico.index[0]),val]=dataList[val]\n",
    "#newEdit[['idtabla','estudio','descripcion','idestudio']]\n",
    "newEdit.to_csv(FilePathBase,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 'EDGE', 'Col Edge 1023', 333333],\n",
       "       [2, 'EDGE', 'Col Edge4 1024', 8888888],\n",
       "       [3, 'EDGE2', 'pruebaaplicativos01', 555]], dtype=object)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#idEspecifico.add(newEdit)\n",
    "\n",
    "newEdit.to_numpy()\n",
    "#newEdit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download complete!\n"
     ]
    }
   ],
   "source": [
    "#request to extract a specifi image\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "\n",
    "req = requests.get(data1.values[0][1])\n",
    "if req.status_code==200 :\n",
    "    code=data1.values[0][0]\n",
    "    nameImage=f'Img_{code}.jpg'\n",
    "    path=f'tmp/{nameImage}'\n",
    "    with open (path,'wb') as file:\n",
    "        file.write(req.content)\n",
    "    print('Download complete!')\n",
    "    #i = Image.open(BytesIO(req.content))\n",
    "else: print(f'Error Status Code {req.status_code}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'mysql.connector.cursor_cext.CMySQLCursor'>\n",
      "('265', '#I|265#N|170#B|1#C|10', datetime.datetime(2022, 12, 21, 17, 4, 48), 'Inactivo', 'COLOMBIA', '1', 2023, 'EDGE', 'BEBIDAS NO ALCOHOLICAS', 'CATEGORIA', 'LECHE LIQUIDA', '#I|265#N|170#B|1#C|10', 'TASA', 'BARRANQUILLA,BOGOTA,BUCARAMANGA,CALI,CARTAGENA,EJE CAFETERO,IBAGUE,MEDELLIN,NEIVA,SANTA MARTA', 'Autoservicio,Cafeteria,Panaderia,Tienda', 'ALPINA,ALQUERIA', None, '2022/12/21 08:31:31', 'EDGE', None, None)\n",
      "('265', '#I|265#N|170#B|1#C|10#M|0#R|0', datetime.datetime(2022, 12, 21, 17, 4, 48), 'Inactivo', 'COLOMBIA', '1', 2023, 'EDGE', 'BEBIDAS NO ALCOHOLICAS', 'CATEGORIA,FABRICANTE,MARCA', 'LECHE LIQUIDA,OTROS FABRICANTES,OTRAS MARCAS', '#I|265#N|170#B|1#C|10#M|0#R|0', 'CARAS REGULAR,PRESENCIA,PRESENCIA DECLARADA', 'CALI,EJE CAFETERO', 'Autoservicio,Cafeteria,Panaderia,Tienda', 'ALPINA,ALQUERIA', None, '2022/12/21 08:31:31', 'EDGE', None, None)\n",
      "('265', '#I|265#N|170#B|1#C|10#M|0#R|0#A|8_3', datetime.datetime(2022, 12, 21, 17, 4, 48), 'Inactivo', 'COLOMBIA', '1', 2023, 'EDGE', 'BEBIDAS NO ALCOHOLICAS', 'CATEGORIA,FABRICANTE,MARCA,TIPO', 'LECHE LIQUIDA,OTROS FABRICANTES,OTRAS MARCAS,DESLACTOSADA', '#I|265#N|170#B|1#C|10#M|0#R|0#A|8_3', 'PRESENCIA,PRESENCIA DECLARADA', 'BARRANQUILLA,BOGOTA,BUCARAMANGA,CALI,CARTAGENA,EJE CAFETERO,IBAGUE,MEDELLIN,NEIVA,SANTA MARTA', 'Autoservicio,Cafeteria,Panaderia,Tienda', 'ALPINA,ALQUERIA', None, '2022/12/21 08:31:31', 'EDGE', None, None)\n",
      "('265', '#I|265#N|170#B|1#C|10#M|0#R|0#A|8_6', datetime.datetime(2022, 12, 21, 17, 4, 48), 'Inactivo', 'COLOMBIA', '1', 2023, 'EDGE', 'BEBIDAS NO ALCOHOLICAS', 'CATEGORIA,FABRICANTE,MARCA,TIPO', 'LECHE LIQUIDA,OTROS FABRICANTES,OTRAS MARCAS,ENTERA', '#I|265#N|170#B|1#C|10#M|0#R|0#A|8_6', 'PRESENCIA,PRESENCIA DECLARADA', 'BARRANQUILLA,BOGOTA,BUCARAMANGA,CALI,CARTAGENA,EJE CAFETERO,IBAGUE,MEDELLIN,NEIVA,SANTA MARTA', 'Autoservicio,Cafeteria,Panaderia,Tienda', 'ALPINA,ALQUERIA', None, '2022/12/21 08:31:31', 'EDGE', None, None)\n",
      "('265', '#I|265#N|170#B|1#C|10#M|100#R|163', datetime.datetime(2022, 12, 21, 17, 4, 48), 'Inactivo', 'COLOMBIA', '1', 2023, 'EDGE', 'BEBIDAS NO ALCOHOLICAS', 'CATEGORIA,FABRICANTE,MARCA', 'LECHE LIQUIDA,ALIVAL,SAN FERNANDO', '#I|265#N|170#B|1#C|10#M|100#R|163', 'CARAS REGULAR,PRESENCIA,PRESENCIA DECLARADA', 'CALI,EJE CAFETERO', 'Autoservicio,Cafeteria,Panaderia,Tienda', 'ALPINA,ALQUERIA', None, '2022/12/21 08:31:31', 'EDGE', None, None)\n",
      "('265', '#I|265#N|170#B|1#C|10#M|100#R|163#A|8_3#A|4_1#A|2_0', datetime.datetime(2022, 12, 21, 17, 4, 48), 'Inactivo', 'COLOMBIA', '1', 2023, 'EDGE', 'BEBIDAS NO ALCOHOLICAS', 'CATEGORIA,FABRICANTE,MARCA,TIPO,EMPAQUE,CONTENIDO', 'LECHE LIQUIDA,ALIVAL,SAN FERNANDO,DESLACTOSADA,BOLSA,OTRO(A)', '#I|265#N|170#B|1#C|10#M|100#R|163#A|8_3#A|4_1#A|2_0', 'PRESENCIA', 'CALI,EJE CAFETERO', 'Autoservicio,Cafeteria,Panaderia,Tienda', 'ALPINA,ALQUERIA', None, '2022/12/21 08:31:31', 'EDGE', None, None)\n",
      "('265', '#I|265#N|170#B|1#C|10#M|100#R|163#A|8_3#A|4_1#A|2_16', datetime.datetime(2022, 12, 21, 17, 4, 48), 'Inactivo', 'COLOMBIA', '1', 2023, 'EDGE', 'BEBIDAS NO ALCOHOLICAS', 'CATEGORIA,FABRICANTE,MARCA,TIPO,EMPAQUE,CONTENIDO', 'LECHE LIQUIDA,ALIVAL,SAN FERNANDO,DESLACTOSADA,BOLSA,1100 ML', '#I|265#N|170#B|1#C|10#M|100#R|163#A|8_3#A|4_1#A|2_16', 'PRESENCIA,PRESENCIA DECLARADA', 'CALI,EJE CAFETERO', 'Autoservicio,Cafeteria,Panaderia,Tienda', 'ALPINA,ALQUERIA', None, '2022/12/21 08:31:31', 'EDGE', None, None)\n",
      "('265', '#I|265#N|170#B|1#C|10#M|100#R|163#A|8_6#A|4_1#A|2_0', datetime.datetime(2022, 12, 21, 17, 4, 48), 'Inactivo', 'COLOMBIA', '1', 2023, 'EDGE', 'BEBIDAS NO ALCOHOLICAS', 'CATEGORIA,FABRICANTE,MARCA,TIPO,EMPAQUE,CONTENIDO', 'LECHE LIQUIDA,ALIVAL,SAN FERNANDO,ENTERA,BOLSA,OTRO(A)', '#I|265#N|170#B|1#C|10#M|100#R|163#A|8_6#A|4_1#A|2_0', 'PRESENCIA', 'CALI,EJE CAFETERO', 'Autoservicio,Cafeteria,Panaderia,Tienda', 'ALPINA,ALQUERIA', None, '2022/12/21 08:31:31', 'EDGE', None, None)\n",
      "('265', '#I|265#N|170#B|1#C|10#M|100#R|163#A|8_6#A|4_1#A|2_16', datetime.datetime(2022, 12, 21, 17, 4, 48), 'Inactivo', 'COLOMBIA', '1', 2023, 'EDGE', 'BEBIDAS NO ALCOHOLICAS', 'CATEGORIA,FABRICANTE,MARCA,TIPO,EMPAQUE,CONTENIDO', 'LECHE LIQUIDA,ALIVAL,SAN FERNANDO,ENTERA,BOLSA,1100 ML', '#I|265#N|170#B|1#C|10#M|100#R|163#A|8_6#A|4_1#A|2_16', 'PRESENCIA,PRESENCIA DECLARADA', 'CALI,EJE CAFETERO', 'Autoservicio,Cafeteria,Panaderia,Tienda', 'ALPINA,ALQUERIA', None, '2022/12/21 08:31:31', 'EDGE', None, None)\n",
      "('265', '#I|265#N|170#B|1#C|10#M|116#R|138', datetime.datetime(2022, 12, 21, 17, 4, 48), 'Inactivo', 'COLOMBIA', '1', 2023, 'EDGE', 'BEBIDAS NO ALCOHOLICAS', 'CATEGORIA,FABRICANTE,MARCA', 'LECHE LIQUIDA,ALPINA,ALPINA', '#I|265#N|170#B|1#C|10#M|116#R|138', 'CARAS REGULAR,PRESENCIA,PRESENCIA DECLARADA', 'CALI,EJE CAFETERO', 'Autoservicio,Cafeteria,Panaderia,Tienda', 'ALPINA,ALQUERIA', None, '2022/12/21 08:31:31', 'EDGE', None, None)\n"
     ]
    }
   ],
   "source": [
    "from mysql.connector import connect , Error\n",
    "\n",
    "class DB():\n",
    "    def __init__(self):\n",
    "        self.host='meiko-prod.cmebrzxfmsvx.us-east-2.rds.amazonaws.com'\n",
    "        self.user='support_data'\n",
    "        self.password='puHnBWtMOzQzHarQMhnmhooy'\n",
    "        self.port=3306\n",
    "        \n",
    "        \n",
    "    def _newQuery(self, query):\n",
    "        try:\n",
    "            with connect(\n",
    "                host= self.host,\n",
    "                user= self.user,\n",
    "                password=self.password,\n",
    "                #self.port\n",
    "            ) as connection:\n",
    "                with connection.cursor() as cursor:\n",
    "                    return cursor.execute(query)\n",
    "        except Error as e:\n",
    "            return f'An Error ocurred {e}'\n",
    "        \n",
    "        \n",
    "import mysql.connector\n",
    "\n",
    "config = {\n",
    "  'user': 'support_data',\n",
    "  'password': 'puHnBWtMOzQzHarQMhnmhooy',\n",
    "  'host': 'meiko-prod.cmebrzxfmsvx.us-east-2.rds.amazonaws.com',\n",
    "  'database': 'jobOrder',\n",
    "  'port':3306,\n",
    "  'raise_on_warnings': True\n",
    "}\n",
    "\n",
    "cnx = mysql.connector.connect(**config)\n",
    "query = (\"SELECT * FROM jobOrder.sp_mega_job_nf WHERE anio =2023 LIMIT 10\")\n",
    "cursor=cnx.cursor()\n",
    "cursor.execute(query)\n",
    "\n",
    "print(type(cursor))\n",
    "for row in cursor:\n",
    "    print(row)\n",
    "\n",
    "cursor.close()\n",
    "cnx.close()\n",
    "        \n",
    "\n",
    "#newq=DB()  \n",
    "#print(newq._newQuery('SELECT * FROM jobOrder.sp_mega_job_nf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "################ MApeo de datos Hash verification\n",
    "import mysql.connector\n",
    "import pprint\n",
    "\n",
    "config = {\n",
    "  'user': 'support_data',\n",
    "  'password': 'puHnBWtMOzQzHarQMhnmhooy',\n",
    "  'host': 'meiko-prod.cmebrzxfmsvx.us-east-2.rds.amazonaws.com',\n",
    "  'database': 'jobOrder',\n",
    "  'port':3306,\n",
    "  'raise_on_warnings': True\n",
    "}\n",
    "\n",
    "cnx = mysql.connector.connect(**config)\n",
    "listQuery={}\n",
    "\n",
    "listQuery['querySpMegaJob'] = (f\"\"\"SELECT\n",
    "\tDISTINCT llave_job AS HASHMGJ, ll.tipos_medicion \n",
    "FROM\n",
    "\tjobOrder.sp_mega_job_nf ll\n",
    "WHERE\n",
    "\testado_job = 'Activo'\n",
    "\tAND ciclo = 'm3'\n",
    "\tAND anio = '2023'\n",
    "\tAND pais = 'COLOMBIA'\n",
    "\tAND estudio  = 'ESPECIAL'\n",
    "\tAND tipos_medicion LIKE '%%'\n",
    "\tAND empresas LIKE '%PINTUCO%';\"\"\")\n",
    "\n",
    "listQuery['queryViewMapeoDatos']=\"\"\"\n",
    "SELECT\n",
    "\tDISTINCT llave_job AS HASHMGJ, ll.tipos_medicion \n",
    "FROM\n",
    "\tjobOrder.sp_mega_job_nf ll\n",
    "WHERE\n",
    "\testado_job = 'Activo'\n",
    "\tAND ciclo = 'm3'\n",
    "\tAND anio = '2023'\n",
    "\tAND pais = 'COLOMBIA'\n",
    "\tAND estudio  = 'ESPECIAL'\n",
    "\tAND tipos_medicion LIKE '%%'\n",
    "\tAND empresas LIKE '%PINTUCO%';\n",
    "\"\"\"  \n",
    "cursor=cnx.cursor()\n",
    "newdict={}\n",
    "q={}\n",
    "resultlist ={}\n",
    "typesMed=[]\n",
    "for key,itemQuery in listQuery.items():\n",
    "  cursor.execute(itemQuery)\n",
    "  q[key]=cursor.fetchall()\n",
    "  for row in q[key]:\n",
    "      typesMed+=str(row[1]).split(',')\n",
    "      for meditionType in typesMed:\n",
    "          print(newdict)\n",
    "          if not meditionType in newdict.keys():\n",
    "              newdict[meditionType]=[]\n",
    "          \n",
    "          if meditionType in row[1]:\n",
    "            newdict[meditionType]=newdict[meditionType]+[row[0]]\n",
    "      resultlist[key]=newdict\n",
    "  \n",
    "          \n",
    "#       \n",
    "#for meditionType in typesMed:\n",
    "#  if not meditionType in newdict.keys(): #id the medition type is not in the new dict\n",
    "#      newdict[meditionType]=[] #then add key with an ampyt list []\n",
    "#      if meditionType in row[1]: \n",
    "#          newdict[meditionType]=newdict[meditionType]+[row[0]] # add to the group each hash \n",
    "#print(newdict)  \n",
    "print(resultlist) \n",
    "cursor.close()\n",
    "cnx.close()\n",
    "#{'spMegaJOb':{\n",
    "#\t'PResencia':['1','2']\n",
    "#},}\n",
    "#pprint.pprint(newdict)  \n",
    "#print(newdict.keys())\n",
    "#newq=DB()  \n",
    "#print(newq._newQuery('SELECT * FROM jobOrder.sp_mega_job_nf'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "ProgrammingError",
     "evalue": "2055: Cursor is not connected",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mProgrammingError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\luis.chaparro\\Documents\\coding-py\\ocr\\.venv\\lib\\site-packages\\mysql\\connector\\cursor_cext.py:300\u001b[0m, in \u001b[0;36mCMySQLCursor.execute\u001b[1;34m(self, operation, params, multi)\u001b[0m\n\u001b[0;32m    299\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cnx \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cnx\u001b[39m.\u001b[39mis_closed():\n\u001b[1;32m--> 300\u001b[0m         \u001b[39mraise\u001b[39;00m ProgrammingError\n\u001b[0;32m    301\u001b[0m \u001b[39mexcept\u001b[39;00m (ProgrammingError, \u001b[39mReferenceError\u001b[39;00m) \u001b[39mas\u001b[39;00m err:\n",
      "\u001b[1;31mProgrammingError\u001b[0m: Unknown error",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mProgrammingError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\luis.chaparro\\Documents\\coding-py\\ocr\\pdtableconn.ipynb Cell 12\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/luis.chaparro/Documents/coding-py/ocr/pdtableconn.ipynb#X51sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m# Iterate through the queries in listQuery\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/luis.chaparro/Documents/coding-py/ocr/pdtableconn.ipynb#X51sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mfor\u001b[39;00m query_name, query_string \u001b[39min\u001b[39;00m listQuery\u001b[39m.\u001b[39mitems():\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/luis.chaparro/Documents/coding-py/ocr/pdtableconn.ipynb#X51sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     cursor\u001b[39m.\u001b[39;49mexecute(query_string)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/luis.chaparro/Documents/coding-py/ocr/pdtableconn.ipynb#X51sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     query_results \u001b[39m=\u001b[39m cursor\u001b[39m.\u001b[39mfetchall()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/luis.chaparro/Documents/coding-py/ocr/pdtableconn.ipynb#X51sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     \u001b[39m# Initialize a dictionary for this query\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\luis.chaparro\\Documents\\coding-py\\ocr\\.venv\\lib\\site-packages\\mysql\\connector\\cursor_cext.py:302\u001b[0m, in \u001b[0;36mCMySQLCursor.execute\u001b[1;34m(self, operation, params, multi)\u001b[0m\n\u001b[0;32m    300\u001b[0m         \u001b[39mraise\u001b[39;00m ProgrammingError\n\u001b[0;32m    301\u001b[0m \u001b[39mexcept\u001b[39;00m (ProgrammingError, \u001b[39mReferenceError\u001b[39;00m) \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m--> 302\u001b[0m     \u001b[39mraise\u001b[39;00m ProgrammingError(\u001b[39m\"\u001b[39m\u001b[39mCursor is not connected\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m2055\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m    303\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cnx\u001b[39m.\u001b[39mhandle_unread_result()\n\u001b[0;32m    305\u001b[0m stmt \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n",
      "\u001b[1;31mProgrammingError\u001b[0m: 2055: Cursor is not connected"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize the resultList dictionary\n",
    "resultList = {}\n",
    "\n",
    "# Iterate through the queries in listQuery\n",
    "for query_name, query_string in listQuery.items():\n",
    "    cursor.execute(query_string)\n",
    "    query_results = cursor.fetchall()\n",
    "\n",
    "    # Initialize a dictionary for this query\n",
    "    query_dict = {}\n",
    "\n",
    "    # Iterate through the query results\n",
    "    for row in query_results:\n",
    "        values = row[0]  # Assuming the values are in the first column\n",
    "        tipos_medicion = str(row[1]).split(',')\n",
    "\n",
    "        for tipo_medicion in tipos_medicion:\n",
    "            tipo_medicion = tipo_medicion.strip()  # Remove leading/trailing spaces\n",
    "\n",
    "            if tipo_medicion not in query_dict:\n",
    "                query_dict[tipo_medicion] = [values]\n",
    "            else:\n",
    "                query_dict[tipo_medicion].append(values)\n",
    "\n",
    "    # Add the query_dict to the resultList\n",
    "    resultList[query_name] = query_dict\n",
    "\n",
    "# Print or process the resultList as needed\n",
    "print(resultList)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key,query in listQuery.items():\n",
    "  cursor.execute(query)#qery data \n",
    "  result[key]=cursor.fetchall()#get all record result[key]= conn.qerySelector(Query)\n",
    "  #print(type(result)) #list\n",
    "  for row, value in result.items():#row[1] equal to  'presencia'===['hash', 'Presencia']\n",
    "      print(row)\n",
    "      if  row =='querySpMegaJob':\n",
    "      \ttypesMed=str(row[1]).split(',')\n",
    "        for i in l:\n",
    "           if typesMed==i:#if type of med is present in the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'id_ciclo': 1, 'valor': '1'},\n",
      " {'id_ciclo': 2, 'valor': '2'},\n",
      " {'id_ciclo': 3, 'valor': '3'},\n",
      " {'id_ciclo': 4, 'valor': '4'},\n",
      " {'id_ciclo': 5, 'valor': '5'},\n",
      " {'id_ciclo': 6, 'valor': '6'},\n",
      " {'id_ciclo': 7, 'valor': 'M1'},\n",
      " {'id_ciclo': 8, 'valor': 'M2'},\n",
      " {'id_ciclo': 9, 'valor': 'M3'},\n",
      " {'id_ciclo': 10, 'valor': 'M4'},\n",
      " {'id_ciclo': 11, 'valor': 'M5'},\n",
      " {'id_ciclo': 12, 'valor': 'M6'},\n",
      " {'id_ciclo': 13, 'valor': '7'},\n",
      " {'id_ciclo': 14, 'valor': '8'},\n",
      " {'id_ciclo': 15, 'valor': '9'},\n",
      " {'id_ciclo': 16, 'valor': '10'},\n",
      " {'id_ciclo': 17, 'valor': '11'},\n",
      " {'id_ciclo': 18, 'valor': '12'},\n",
      " {'id_ciclo': 19, 'valor': 'M7'},\n",
      " {'id_ciclo': 20, 'valor': 'M8'},\n",
      " {'id_ciclo': 21, 'valor': 'M9'},\n",
      " {'id_ciclo': 22, 'valor': 'M10'},\n",
      " {'id_ciclo': 23, 'valor': 'M11'},\n",
      " {'id_ciclo': 24, 'valor': 'M12'},\n",
      " {'id_ciclo': 25, 'valor': 'M13'},\n",
      " {'id_ciclo': 26, 'valor': 'M14'},\n",
      " {'id_ciclo': 27, 'valor': 'M15'},\n",
      " {'id_ciclo': 28, 'valor': 'M16'},\n",
      " {'id_ciclo': 29, 'valor': 'M17'},\n",
      " {'id_ciclo': 30, 'valor': 'M18'},\n",
      " {'id_ciclo': 31, 'valor': 'M20'},\n",
      " {'id_ciclo': 32, 'valor': 'M21'},\n",
      " {'id_ciclo': 33, 'valor': 'M22'},\n",
      " {'id_ciclo': 34, 'valor': 'M23'},\n",
      " {'id_ciclo': 35, 'valor': 'M24'}]\n"
     ]
    }
   ],
   "source": [
    "from main import DB\n",
    "import pprint\n",
    "\n",
    "conn1=DB()\n",
    "\n",
    "ctxhash={}\n",
    "ctxhash['countries']='''select * from geomaster.paises;'''\n",
    "ctxhash['cycles']='''select * from jobOrder.ciclos;'''\n",
    "ctxhash['studies']='''select * from jobOrder.estudios;'''\n",
    "ctxhash['clients']='''select * from jobOrder.clientes; '''\n",
    "ctxhash['meditionTypes']='''SELECT\tDISTINCT tipos_medicion FROM jobOrder.sp_mega_job_nf; '''\n",
    "for val in ctxhash:\n",
    "    v1=ctxhash[val]\n",
    "    ctxhash[val]=conn1._newQuerySelect(v1)\n",
    "\n",
    "pprint.pprint(ctxhash['cycles'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testProcess(idStudio,tpst='pruebas', finicio ='' , ffin ='', nrecord=30):\n",
    "    url,req, result ={},{},{}\n",
    "    path=Path('tmp',f'Studytest{idStudio}_{tpst}.csv')\n",
    "    url['pruebas'] =f'https://www.easysalespruebas.com.co/ServiciosEasySurvey/api/ObtenerExportadoEncuesta?usuario=EasySurveyClientMeiko&password=EasySurveyClientMeiko&id_encuesta={idStudio}&idr_encabezado=0'\n",
    "    url['produccion']= f'https://www.easysalespruebas.com.co/ServiciosEasySurvey/api/ObtenerExportadoEncuestaRangoFechaRecepcion?usuario=EasySurveyClientMeiko&password=EasySurveyClientMeiko&id_encuesta={idStudio}&fecha_inicial={finicio}000000&fecha_final={ffin}235959'\n",
    "    if tpst == 'pruebas':\n",
    "        req['pruebas'] = requests.get(url['pruebas'])\n",
    "    elif tpst == 'produccion':\n",
    "        req['produccion'] = requests.get(url['produccion'])\n",
    "    elif tpst == 'ambos':\n",
    "        for key, value in url.items():\n",
    "            req[key]=requests.get(value)\n",
    "    \n",
    "    # req = {'ambiete':{\n",
    "    #    req.methods\n",
    "    #}}\n",
    "    \n",
    "    #k = ambiente\n",
    "    #v\n",
    "    for k in req.keys():\n",
    "        if req[k].status_code==200:\n",
    "            #falta modulo de eliminacion archivos temporales estudios slecionados por nombre\n",
    "            with open(path, 'wb') as file:\n",
    "                file.write(req[k].content)\n",
    "                file.close()\n",
    "\n",
    "            with open(path, 'rb') as fileRead:\n",
    "                line_count = sum(1 for line in fileRead)\n",
    "                if line_count <=2 :\n",
    "                    result[k] =[{'Informacion':f'No hay registros #{line_count}'} ]\n",
    "                else:\n",
    "                    data= pd.read_csv(path).tail(nrecord)\n",
    "                    data= data[['Auditor','Response.Received','Descripcion','responseModified','ENCUESTADOR','pre_nombreestablecimiento']]\n",
    "\n",
    "                    #result=data.to_numpy()\n",
    "                    result[k]=data.to_dict(orient='records')\n",
    "                    #result=data.to_html(classes='table table-striped tablacss')\n",
    "                    #f1=result.shape\n",
    "                    #result=data.to_html(classes='table table-dark')\n",
    "                    \n",
    "#[lambda ambiente: req[ambiente].status_code if req[ambiente].status_code == 200 else f'Error en la consulta Estudio no encontrado http:{req[ambiente].status_code}'](ambiente) for ambiente in req]\n",
    "#status_codes = [req[ambiente].status_code if req[ambiente].status_code == 200 else f'Error en la consulta Estudio no encontrado http:{req[ambiente].status_code}' for ambiente in req]\n",
    "        else: result[k]= [{'Informacion':f'Error en la consulta Estudio no encontrado  http:{k} : {req[k].status_code} '} ]\n",
    "    return result\n",
    "\n",
    "result= testProcess(352,tpst='ambos', finicio ='' , ffin ='', nrecord=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Studytest1092.csv\n",
      "Studytest1100.csv\n",
      "Studytest314.csv\n",
      "Studytest316.csv\n",
      "Studytest3398.csv\n",
      "Studytest3400.csv\n",
      "Studytest3400_produccion.csv\n",
      "Studytest3400_pruebas.csv\n",
      "Studytest352.csv\n",
      "Studytest352_ambos.csv\n",
      "Studytest357_ambos.csv\n",
      "Studytest357_pruebas.csv\n",
      "Studytest392.csv\n",
      "Studytest392_ambos.csv\n",
      "Studytest392_pruebas.csv\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "listFile=os.listdir(path='tmp')\n",
    "matching_files = [filename for filename in listFile if re.match(f'Studytest_*', filename)]\n",
    "for i in range(0,len(matching_files)):\n",
    "    if os.path.exists(path='tmp/'+matching_files[i]):\n",
    "        os.remove()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
